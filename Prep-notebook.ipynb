{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import cv2 as cv\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "On procède à la séparation du dataset d'entrainement en deux sous partie : entrainement et validation a^rès avoir fait un filtrage médian \n",
    "### Filtrage médian de toutes les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_img(path_to_data, path_to_save) :\n",
    "    folders = os.listdir(path_to_data)\n",
    "    for folder in folders : \n",
    "        path1 = os.path.join(path_to_data,folder)\n",
    "        sub_folders = os.listdir(path1)\n",
    "        for sub_folder in sub_folders :\n",
    "            full_path = os.path.join(path1, sub_folder)\n",
    "            images = os.listdir(full_path)\n",
    "            for image in images : \n",
    "                path_to_image = os.path.join(full_path,image)\n",
    "                myimage = cv.imread(path_to_image)\n",
    "                myimage_med = cv.medianBlur(myimage,3)\n",
    "                path_save1 = os.path.join(path_to_save,folder,sub_folder)\n",
    "                path_save2 = os.path.join(path_save1,image)\n",
    "                if not os.path.isdir(path_save1) : \n",
    "                    os.makedirs(path_save1)\n",
    "                cv.imwrite(path_save2,myimage_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./Dataset\"\n",
    "path_to_save = \"./DatasetMedian\"\n",
    "median_img(path_to_data,path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On subdivise maintenant le dataset d'entrainement en deux : entrainement et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val(path_to_data, path_to_save_train, path_to_save_val, split_size=0.1) :\n",
    "    folders = os.listdir(path_to_data) # la liste des dossiers disponible au chemin donné\n",
    "    for folder in folders :\n",
    "        full_path = os.path.join(path_to_data, folder) # pour avoir le chemin complet en ajoutant le nom des dossiers\n",
    "        images_paths = glob.glob(os.path.join(full_path, '*.jpg')) # ca prend tous les fichiers à l'intérieur du dossier et les télécharge (le join il va a chaque fois ajouter le path du dossier et ajoutant le nom du fichier) ca nous retourne une liste d'images\n",
    "        x_train, x_val = train_test_split(images_paths, test_size=split_size) # split en train et validation\n",
    "\n",
    "        for x in x_train : \n",
    "            path_to_folder = os.path.join(path_to_save_train, folder) # pour recréer les même dossier que dans le dossier de base\n",
    "            if not os.path.isdir(path_to_folder) : \n",
    "                os.makedirs(path_to_folder) # si il n'existe pas il le crée\n",
    "            shutil.copy(x, path_to_folder)\n",
    "        \n",
    "        for x in x_val : \n",
    "            path_to_folder = os.path.join(path_to_save_val, folder) # pour recréer les même dossier que dans le dossier de base\n",
    "            if not os.path.isdir(path_to_folder) : \n",
    "                os.makedirs(path_to_folder) # si il n'existe pas il le crée\n",
    "            shutil.copy(x, path_to_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise maintenant les données filtrées, on garde le dossier d'entrainement de base, on ajoute deux dossiers : \n",
    "- Training \n",
    "- Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"./DatasetMedian/train\"\n",
    "path_to_save_train = \"./DatasetMedian/Training\"\n",
    "path_to_save_val = \"./DatasetMedian/Validation\"\n",
    "split_train_val(path_to_data, path_to_save_train, path_to_save_val)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "374be8c39ae01ff66328729506a9b9a7ba9eb3f2df141c8f3098ad96d8cc6bdd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
